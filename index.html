<html>

<head>
    <meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
    <link rel="stylesheet" type="text/css" href="style.css" />
    <title>Fan Yang's Home Page</title>
    <base href="index.html">
</head>

<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<h1 style="padding-left: 0.5em">Fan Yang's Home Page</h1><hr>
<td id="layout-menu">
    <div class="menu-item"><a href="index.html" class="current">Home</a></div>
    <div class="menu-item"><a href="publication.html">Publications</a></div>
</td>
<td id="layout-content">

    <h1 style="margin-top: 0em">Home</h1><br>
    <p>[ <a href="#bio">Short Biography</a>,
         <a href="#interest">Research Interests</a>,
         <a href="#job">Research Experience</a>,
         <a href="#edu">Education</a> ]</p>

    <table class="imgtable"><tr valign="top">
        <td><img src="fan.jpg" alt="fan yang" style="width:8em; height:auto" /></td>
        <td align="left">
            <p><span style="font-size: 110%"><b>Fan Yang, Ph.D.</b></span></p>
            <p>
                Senior Scientist<br>
                <a href="https://aiqintelligence.ae/" target="_blank">AIQ</a>
            </p>
            <p>
                E-mail: <b>fanyang_uestc@hotmail.com</b><br>
				<img src="images/google.png" alt="google" style="width:0.8em; height:auto" />&nbsp;&nbsp;<a href="https://scholar.google.com/citations?user=FSfSgwQAAAAJ&hl=en" target="_blank">Google Scholar</a><br>
                <img src="images/dblp.png" alt="google" style="width:1.1em; height:auto" />&nbsp;&nbsp;<a href="https://dblp.org/pid/29/3081-54.html" target="_blank">DBLP</a><br>
				<img src="images/git.png" alt="google" style="width:1em; height:auto" />&nbsp;&nbsp;<a href="https://github.com/fanyang587" target="_blank">Github</a>
            </p>
        </td>
    </tr></table>
    
    <!-- <p><font color="#FF0000">We are organizing an <b>IJCAI 2021 workshop</b> on <b>weakly supervised representation learning</b>
    <a href="http://wsl-workshop.github.io/" target="_blank">(CFP)</a><br>
    as well as a <b>special issue of Machine Learning journal</b> on the same topic
    <a href="http://www.springer.com/journal/10994/updates/19149940" target="_blank">(CFP)</a>. Welcome to submit!</font></p> -->
    
    <div>
        <h2><hr><a name="bio"></a>Short Biography</h2>
        <p style="text-align:justify; text-justify:inter-ideograph;">
            Fan Yang received the B.S. degree in software engineering from Southwest Petroleum University in 2010, and the Doctorâ€™s degree in information and communication engineering from University of Electronic Science and Technology of China (UESTC), in 2018. He was a research intern with Microsoft Research Asia (MSRA). He was a research scholar in the department of computer science, University of North Carolina and also in the department of Radiology and BRIC, University of North Carolina. He was Research Associate in IIAI. Now, he is a senior scientist with <a href="https://aiqintelligence.ae/" target="_blank">AIQ</a>, UAE. His research interests include computer vision, deep learning and medical image processing. 
        </p>
    </div>

    <div>
        <h2><hr><a name="interest"></a>Research Interests</h2>
        <ul>
            <li><p>Image Segmentation</p></li>
			<li><p>3D Vision</p></li>
			<li><p>Medical Image Analysis</p></li>
			<li><p>Machine learning</p></li>
        </ul>
    </div>

    <div>
        <h2><hr><a name="job"></a>Research Experience</h2>
        <ul>
            <li><p>
                <b>Senior Scientist</b> (March 2020--Now)<br>
              AIQ, Abu Dhabi, UAE.<br>
				
			</p>
            </li>
            <li><p>
                <b>Research Associate</b> (March 2019--March 2020)<br>
                Inception Institute of Artificial Intelligence, Abu Dhabi, UAE.
            </p></li>
            <li><p>
                <b>Post Doctoral</b> (August 2018--March 2019)<br>
                IDEA Research Lab in the Department of Radiology, University of North Carolina at Chapel Hill, NC, USA.
            </p></li>
            <li><p>
                <b>Research Intern</b> (September 2016--April 2017)<br>
                Microsoft Research Asia, Beijing, China.
            </p></li>
        </ul>
    </div>

    <div>
        <h2><hr><a name="edu"></a>Education</h2>
        <ul>
            <li><p>
                <b>PhD. student</b> (September 2012--June 2018)<br>
                School of Computer Science and Engineering,<br>
				University of Electronic Science and Technology of China, Chengdu, China.<br>
                Advisor: Professor Hong Cheng & Professor Jianping Li.
            </p></li>
            <li><p>
                <b>M.S. student</b> (September 2010--June 2012)<br>
                School of Computer Science and Engineering,<br>
				University of Electronic Science and Technology of China, Chengdu, China.<br>
                Advisor: Professor Jianping Li.
            </p></li>
            <li><p>
                <b>B.S. student</b> (September 2006--June 2010)<br>
                School of Computer Science,<br>
				Southwest Petroleum University, Xindu, China.<br>
                Major: Software Engineering.
            </p></li>
        </ul>
    </div>
	<div>
        <h2><hr><a name="edu"></a>Selected Publication</h2>
        <table class="imgtable">

		<tr valign="top">
        <td><img src="images/flowdiffuser.png" alt="fan yang" style="width:10em; height:5.6em" /></td>
			<td align="left">
			<p>
			FlowDiffuser: Advancing Optical Flow Estimation with Diffusion Models<br>
			Ao Luo, Xin Li, <b>Fan Yang</b>, Jiangyu Liu, Haoqiang Fan and Shuaicheng Liu.<br>
			In <i>Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV), 2023.</i><br>
			[<a href="">PDF</a>]
			</p>
			</td>
		</tr>
		
		<tr valign="top">
        <td><img src="images/gaflow.jpg" alt="fan yang" style="width:10em; height:5.6em" /></td>
			<td align="left">
			<p>
			GAFlow: Incorporating Gaussian Attention into Optical Flow<br>
			Ao Luo, <b>Fan Yang</b>, Xin Li, Lang Nie, Chunyu Lin, Haoqiang Fan and Shuaicheng Liu.<br>
			In <i>Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV), 2023.</i><br>
			[<a href="https://openaccess.thecvf.com/content/ICCV2023/papers/Luo_GAFlow_Incorporating_Gaussian_Attention_into_Optical_Flow_ICCV_2023_paper.pdf">PDF</a>]
			</p>
			</td>
		</tr>
			
		<tr valign="top">
        <td><img src="images/kpa.png" alt="fan yang" style="width:10em; height:5.6em" /></td>
			<td align="left">
			<p>
			Learning Optical Flow with Kernel Patch Attention<br>
			Ao Luo, <b>Fan Yang</b>, Xin Li and Shuaicheng Liu.<br>
			In <i>Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2022.</i><br>
			[<a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Luo_Learning_Optical_Flow_With_Kernel_Patch_Attention_CVPR_2022_paper.pdf">PDF</a>]
			</p>
			</td>
		</tr>
		
		<tr valign="top">
        <td><img src="images/flow1.png" alt="fan yang" style="width:10em; height:5.6em" /></td>
			<td align="left">
			<p>
			Learning Optical Flow with Adaptive Graph Reasoning<br>
			Ao Luo, <b>Fan Yang</b>, Kunming Luo, Xin Li, Haoqiang Fan and Shuaicheng Liu.<br>
			In <i>Proceedings of 36th AAAI Conference on Artificial Intelligence (AAAI), 2022.</i><br>
			[<a href="https://www.aaai.org/AAAI22Papers/AAAI-1843.LuoA.pdf">PDF</a>]
			</p>
			</td>
		</tr>

		<tr valign="top">
        <td><img src="images/ugtr.png" alt="fan yang" style="width:10em; height:5.6em" /></td>
			<td align="left">
			<p>
			Uncertainty-Guided Transformer Reasoning for Camouflaged Object Detection<br>
			<b>Fan Yang</b>, Qiang Zhai, Xin Li, Rui Huang, Ao Luo, Hong Cheng and Deng-Ping Fan.<br>
			In <i>Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV), 2021.</i><br>
			[<a href="https://openaccess.thecvf.com/content/ICCV2021/papers/Yang_Uncertainty-Guided_Transformer_Reasoning_for_Camouflaged_Object_Detection_ICCV_2021_paper.pdf" target="_blank">PDF</a>] [<a href="https://github.com/fanyang587/UGTR" target="_blank">Github</a>]
			</p>
			</td>
		</tr>

		<tr valign="top">
        <td><img src="images/mgl.png" alt="fan yang" style="width:10em; height:5.6em" /></td>
			<td align="left">
			<p>
			Mutual Graph Learning for Camouflaged Object Detection<br>
			Qiang Zhai, Xin Li, <b>Fan Yang</b>, Chenglizhao Chen, Hong Cheng and Deng-Ping Fan.<br>
			In <i>Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2021.</i><br>
			[<a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Zhai_Mutual_Graph_Learning_for_Camouflaged_Object_Detection_CVPR_2021_paper.pdf" target="_blank">PDF</a>] [<a href="https://arxiv.org/pdf/2104.02613.pdf" target="_blank">arXiv</a>][<a href="https://github.com/fanyang587/MGL" target="_blank">Github</a>]
			</p>
			</td>
		</tr>
		
		<tr valign="top">
        <td><img src="images/pmd.png" alt="fan yang" style="width:10em; height:5.6em" /></td>
			<td align="left">
			<p>
			Probabilistic Model Distillation for Semantic Correspondence<br>
			Xin Li, Deng-Ping Fan, <b>Fan Yang</b>, Ao Luo, Hong Cheng, Zicheng Liu.<br>
			In <i>Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2021.</i><br>
			[<a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Li_Probabilistic_Model_Distillation_for_Semantic_Correspondence_CVPR_2021_paper.pdf" target="_blank">PDF</a>] [<a href="https://github.com/fanyang587/PMD" target="_blank">Github</a>]
			</p>
			</td>
		</tr>
			
		<tr valign="top">
        <td><img src="images/rsp.png" alt="fan yang" style="width:10em; height:5.6em" /></td>
			<td align="left">
			<p>
			Robust Scene Parsing by Mining Supportive Knowledge from Dataset<br>
			Ao Luo, <b>Fan Yang</b>, Xin Li, Yuezun Li, Zhicheng Jiao, Hong Cheng and Siwei Lyu.<br>
			<i>IEEE Transactions on Neural Networks and Learning Systems (TNNLS), 2021.</i><br>
			[<a href="https://ieeexplore.ieee.org/abstract/document/9537741" target="_blank">PDF</a>]
			</p>
			</td>
		</tr>
			
		<tr valign="top">
        <td><img src="images/egs.png" alt="fan yang" style="width:10em; height:5.6em" /></td>
			<td align="left">
			<p>
			Exploring Graph-Structured Semantics for Cross-Modal Retrieval<br>
			Lei Zhang, Leiting Chen, Chuan Zhou, <b>Fan Yang</b> and Xin Li.<br>
			<i>ACM International Conference on Multimedia (ACM MM), 2021.</i><br>
			[<a href="https://dl.acm.org/doi/abs/10.1145/3474085.3475567" target="_blank">PDF</a>]
			</p>
			</td>
		</tr>
		
		<tr valign="top">
        <td><img src="images/fmri.png" alt="fan yang" style="width:10em; height:5.6em" /></td>
			<td align="left">
			<p>
			Reconstructing perceived images from brain activity by visually-guided cognitive representation and adversarial learning<br>
			Ziqi Ren, Jie Li, Xuetong Xue, Xin Li, <b>Fan Yang</b>, Zhicheng Jiao, Xinbo Gao.<br>
			<i>NeuroImage, 2021.</i><br>
			[PDF] [<a href="https://arxiv.org/pdf/1906.12181.pdf" target="_blank">arXiv</a>]
			</p>
			</td>
		</tr>
		
		<tr valign="top">
        <td><img src="images/casgnn.png" alt="fan yang" style="width:10em; height:5.6em" /></td>
			<td align="left">
			<p>
			Cascade graph neural networks for rgb-d salient object detection<br>
			Ao Luo, Xin Li, <b>Fan Yang</b>, Zhicheng Jiao, Hong Cheng and Siwei Lyu.<br>
			<i>European Conference on Computer Vision (ECCV), 2020.</i><br>
			[<a href="https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123570341.pdf" target="_blank">PDF</a>] [<a href="https://arxiv.org/pdf/2008.03087.pdf" target="_blank">arXiv</a>]
			</p>
			</td>
		</tr>
		
		<tr valign="top">
        <td><img src="images/hygnn.png" alt="fan yang" style="width:10em; height:5.6em" /></td>
			<td align="left">
			<p>
			Hybrid Graph Neural Networks for Crowd Counting<br>
			Ao Luo, <b>Fan Yang</b>, Xin Li, Dong Nie, Zhicheng Jiao, Shangchen Zhou and Hong Cheng.<br>
			<i>Proceedings of the AAAI Conference on Artificial Intelligence (AAAI), 2020.</i><br>
			[<a href="https://ojs.aaai.org/index.php/AAAI/article/download/6839/6693" target="_blank">PDF</a>] [<a href="https://arxiv.org/pdf/2002.00092.pdf" target="_blank">arXiv</a>]
			</p>
			</td>
		</tr>
		
		<tr valign="top">
        <td><img src="images/eeg.png" alt="fan yang" style="width:10em; height:5.6em" /></td>
			<td align="left">
			<p>
			Decoding EEG by Visual-guided Deep Neural Networks<br>
			Zhicheng Jiao, Haoxuan You, <b>Fan Yang</b>, Xin Li, Han Zhang and Dinggang Shen.<br>
			<i>International Joint Conference on Artificial Intelligence (IJCAI), 2019.</i><br>
			[<a href="https://www.researchgate.net/profile/Han-Zhang-193/publication/334843997_Decoding_EEG_by_Visual-guided_Deep_Neural_Networks/links/5d6e731e45851542789f2465/Decoding-EEG-by-Visual-guided-Deep-Neural-Networks.pdf" target="_blank">PDF</a>]
			</p>
			</td>
		</tr>
		
		<tr valign="top">
        <td><img src="images/c2s.png" alt="fan yang" style="width:10em; height:5.6em" /></td>
			<td align="left">
			<p>
			Contour Knowledge Transfer for Salient Object Detection<br>
			Xin Li, <b>Fan Yang</b>, Hong Cheng, Wei Liu and Dinggang Shen.<br>
			<i> Proceedings of the European Conference on Computer Vision (ECCV), 2018.</i><br>
			[<a href="https://openaccess.thecvf.com/content_ECCV_2018/papers/Xin_Li_Contour_Knowledge_Transfer_ECCV_2018_paper.pdf" target="_blank">PDF</a>] [<a href="https://github.com/lixin666/C2SNet" target="_blank">Github</a>]
			</p>
			</td>
		</tr>
		
		<tr valign="top">
        <td><img src="images/msb.png" alt="fan yang" style="width:10em; height:5.6em" /></td>
			<td align="left">
			<p>
			Multi-Scale Bidirectional FCN for Object Skeleton Extraction<br>
			<b>Fan Yang</b>, Xin Li, Hong Cheng, Yuxiao Guo, Leiting Chen and Jianping Li.<br>
			<i> Proceedings of the AAAI Conference on Artificial Intelligence (AAAI), 2018.</i><br>
			[<a href="https://ojs.aaai.org/index.php/AAAI/article/download/12288/12147" target="_blank">PDF</a>] [<a href="https://github.com/fanyang587/MSB-FCN" target="_blank">Github</a>]
			</p>
			</td>
		</tr>
			
		<tr valign="top">
        <td><img src="images/msc.png" alt="fan yang" style="width:10em; height:5.6em" /></td>
			<td align="left">
			<p>
			Multi-Scale Cascade Network for Salient Object Detection<br>
			Xin Li, <b>Fan Yang</b>,  Hong Cheng, Junyu Chen, Yuxiao Guo and Leiting Chen.<br>
			<i> Proceedings of the ACM International Conference on Multimedia (ACM MM), 2017.</i><br>
			[<a href="https://dl.acm.org/doi/10.1145/3123266.3123290#URLTOKEN#" target="_blank">PDF</a>] [<a href="https://github.com/lixin666/MSC-NET" target="_blank">Github</a>]
			</p>
			</td>
		</tr>
		
		<tr valign="top">
        <td><img src="images/obj.png" alt="fan yang" style="width:10em; height:5.6em" /></td>
			<td align="left">
			<p>
			Object-aware Dense Semantic Correspondence<br>
			<b>Fan Yang</b>, Xin Li, Hong Cheng, Jianping Li and Leiting Chen.<br>
			<i> Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2017.</i><br>
			[<a href="https://openaccess.thecvf.com/content_cvpr_2017/papers/Yang_Object-Aware_Dense_Semantic_CVPR_2017_paper.pdf" target="_blank">PDF</a>]
			</p>
			</td>
		</tr>
		
		<tr valign="top">
        <td><img src="images/st.png" alt="fan yang" style="width:10em; height:5.6em" /></td>
			<td align="left">
			<p>
			Saliency Transfer: An Example-Based Method for Salient Object Detection<br>
			Xin Li, <b>Fan Yang</b>, Leiting Chen and Hongbin Cai.<br>
			<i> Proceedings of the International Joint Conference on Artificial Intelligence (IJCAI), 2016.</i><br>
			[<a href="https://www.ijcai.org/Proceedings/16/Papers/482.pdf" target="_blank">PDF</a>]
			</p>
			</td>
		</tr>
			
	</table>
    </div>
</td>
</tr>
</table>
</body>
</html>
